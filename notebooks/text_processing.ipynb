{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f4faa4d",
   "metadata": {},
   "source": [
    "# Text Processing Pipeline\n",
    "\n",
    "## Introduction\n",
    "\n",
    "After extracting the text data from the file, the next step is to process it by chunking the text into manageable pieces, generating embeddings, and enriching the chunks with keywords. This notebook walks you through each step and the reasoning behind it. We conclude with a discussion of benefits, limitations, and next steps.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Before running this notebook ensure that the local model server is running as we will use it to generate embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28854071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elena/Projects/humana/.venv/lib/python3.12/site-packages\n",
      "Processing time: 0.03 seconds\n",
      "\n",
      "Title: Human Breast Cancer: Correlation of Relapse and Survival with Amplification of the HER-2lneu Oncogene\n",
      "Authors: DENNIS J. SLAMON,* GARY M. CLARK, STEVEN G. WONG, WENDY J. LEVIN, AxEL ULLRICH, WILLiAM L. McGuIRE\n",
      "Body:\n",
      "\n",
      "The HER-2/neu oncoFene is a member of the erbB-like oncogene family, and aS related to, but distinct firom, the epidermal growth factor receptr. This gene has been shown to be amplified i human brt ca...\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import spacy\n",
    "import pytextrank\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Ensure the src directory is in the Python path\n",
    "notebook_dir = Path(os.getcwd())\n",
    "project_root = notebook_dir.parents[0]\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "from src.backend.textExtraction import Article\n",
    "\n",
    "article = Article(\"../corpus/SlamonetalSCIENCE1987.pdf\")\n",
    "\n",
    "\n",
    "start = time()\n",
    "article = Article(\"../corpus/SlamonetalSCIENCE1987.pdf\")\n",
    "end = time()\n",
    "\n",
    "print(f\"Processing time: {end - start:.2f} seconds\\n\")\n",
    "print(f\"Title: {article.title}\")\n",
    "print(f\"Authors: {article.authors}\")\n",
    "\n",
    "print(f\"Body:\\n\\n{article.body[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13ff847",
   "metadata": {},
   "source": [
    "## Chunk Article Body\n",
    "\n",
    "### Why chunk the text?\n",
    "\n",
    "#### 1. Context limit\n",
    "\n",
    "LLM's have a context limit, i.e., a maximum number of tokens they can process during inference. While recent advances have brought about commercial and open-source models with context limits in the 10's or 100's of thousands, many smaller models may not be able to fit the entire article in context. Breaking the article into chunks allows us to use smaller models which only need to read the relevant portions of the document at inference time.\n",
    "\n",
    "In order to serve the model the right portion of the document for a given query, we will implement a retrieval pipeline which will use an embedding model. Similar to LLM's, these embedding models have their own context windows.\n",
    "\n",
    "#### 2. Latency\n",
    "\n",
    "When generating a response, the LLM will need to process each input token before generating its first output token. Even if a model could fit the entire article in context, it would take much longer to respond if we asked it to read the entire article instead of just a relevant snippet.\n",
    "\n",
    "\n",
    "### Chunking Strategy\n",
    "\n",
    "We will be using a fairly standard Recursive Character Text Splitting algorithm, outlined below.\n",
    "\n",
    "The goal is to split text into chunks with:\n",
    "- A maximum chunk size (e.g., 1000 characters)\n",
    "- A minimum amount of overlap between chunks (e.g., 200 characters)\n",
    "- Preserving natural language structure, like paragraphs or sentences, wherever possible\n",
    "\n",
    "You initialize the text splitter with:\n",
    "- `separators`: Ordered list of characters to try splitting on, ordered in descending priority\n",
    "\n",
    "- `chunk_size`: Maximum size of a chunk.\n",
    "\n",
    "- `chunk_overlap`: Number of characters that overlap between adjacent chunks.\n",
    "\n",
    "Algorithm:\n",
    "1. Split the text using the first separator.\n",
    "2. Check the size of each split. For each candidate chunk:\n",
    "    - If it's smaller than or equal to chunk_size, accept it.\n",
    "    - If it's larger than chunk_size, recursively split it using the next separator in the list.\n",
    "3. Repeat Step 2 recursively until all candidate chunks are of an acceptable size. This usually leads to over-splitting.\n",
    "4. Iteratively merge candidate chunks to get as close to the `chunk_size` as possible (without going over) and meet the minimum chunk overlap requirements.\n",
    "\n",
    "#### How to set parameters?\n",
    "\n",
    "**Chunk Size**\n",
    "\n",
    "Downstream, I want to generate embeddings for each chunk using the [MedCPT-Article-Encoder](https://huggingface.co/ncbi/MedCPT-Article-Encoder), an embedding model that was trained on over 255M abstracts from PubMed (more on this below). Because this model was trained on abstracts, I want to make each chunk roughly the same length as an abstract, which are usually between 150-250 words. Taking an average of 5 characters per word this give us between 750-1250 characters on average. This agrees with [this article](https://urds.uoregon.edu/symposium/abstracts) I found from the University of Oregon which gives a typical upper bound of 1500 characters for abstracts. \n",
    "\n",
    "Hence, I will use 1500 maximum chunk size.\n",
    "\n",
    "**Separators**\n",
    "\n",
    "I used the standard list of separators for this library, except I added `\". \"` to try to force more splits at the end of sentences. The goal being to make sure each chunk is interpretable on its own, since the llm won't be able to look back/ahead to get more context.\n",
    "\n",
    "**Chunk Overlap**\n",
    "\n",
    "I set this to 150 characters which roughly equals a sentence or two of overlap. Again, the goal being to make each chunk interpretable on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "897cd28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of chunks: 14\n",
      "Average chunk length: 1260 characters\n",
      "\n",
      "Chunk length: 1018 characters\n",
      "Content:\n",
      "The HER-2/neu oncoFene is a member of the erbB-like oncogene family, and aS related to, but distinct firom, the epidermal growth factor receptr. This gene has been shown to be amplified i human brt cancer cell lines. In the current study, alterations of the gene in 189 primary human breast cancers were instigated HER-2/ neu was found to be amplified frm 2- to eater than 20- fold in 30% of the tumors. Correlation ofgene amplifica- tion with several disease parameters was evaluated Am- plification of the HER-2/neu gene was a significant pre- dictor of both overall survival and time to relapse in patients with breast cancer. It retained its significance even when adjustments were made for other known prognostic factors. Moreover, HER-2/neu amplification had greater prognostic value than most currently used prognostic factors, incuding hormonal-receptor status, in lymph node-positive disease. These data indicate that thbis gene may lay a role in the biologic behavior and/or pathogenesis human breast cancer.\n",
      "\n",
      "Chunk length: 1411 characters\n",
      "Content:\n",
      "HE EVIDENCE LINKING PROTO-ONCOGENES TO THE INDUC- tion or maintenance of human malignancies is largely cir- cumstantial, but has become increasingly compelling. This circumstantial evidence is derived from studies of animal models, tumor cell lines, and actual human tumors. Data from animal models and cell lines include: (i) sequence homology between human proto- oncogenes and the viral oncogenes of transforming retroviruses that are known to be tumorigenic in some species (1, 2); (ii) transfction studies showing the transforming potential of proto-oncogenes m NIH 3T3 cells and primary embryo fibroblasts (3-5); and (iii) the central role of certain proto-oncogenes in tumorigenesis by chronic transforming retroviruses such as avian leukosis virus (6). Data from human tumors include: (i) increased expression of specific proto- oncogenes in some human malignancies (7, 8); (ii) localization of proto-oncogenes at or near the site of specific, tumor-associated chromosomal translocations (9); and (iii) amplification of proto- oncogenes in some human tumors (10, 11). Additional data linking proto-oncogenes to cell growth is their expression in response to certain proliferation signals (12, 13) and their expression during embryonic development (14, 15). More direct evidence comes from the fact that, of the 20 known proto- oncogenes, three are related to a growth factor or a growth factor receptor.\n",
      "\n",
      "Chunk length: 1408 characters\n",
      "Content:\n",
      "More direct evidence comes from the fact that, of the 20 known proto- oncogenes, three are related to a growth factor or a growth factor receptor. These genes include c-sis, which is homologous to thetransforming gene of the simian sarcoma virus and is the 1B chain of platelet-derived growth factor (PDGF) (16, 17); c-fis, which is homologous to the transforming gene of the feline sarcoma virus and is closely related to the macrophage colony-stimulating factor receptor (CSF-1R) (18); and c-erbB, which encodes the EGF receptor (EGFR) and is highly homologous to the transforming gene of the avian erythroblastosis virus (19). The two receptor- related proto-oncogenes, c-fins and c-erbB, are members of the tyrosine-specific protein kinase family to which many proto-onco- genes belong. Recently, a novel transforming gene was identified as a result of transfction studies with DNA from chemically induced rat neu- roglioblastomas (20). This gene, called neu, was shown to be related to, but distinct from, the c-erbB proto-oncogene (21). By means of v-erbB and human EGFR as probes to screen human genomic and complementary DNA (cDNA) libraries, two other groups indepen- dently isolated human erbB-related genes that they called HER-2 (22) and c-erbB-2 (23). Subsequent sequence analysis and chromo- somal mapping studies revealed all three genes (neu, c-erbB-2, and HER-2) to be the same (22, 24, 25).\n",
      "\n",
      "Chunk length: 1359 characters\n",
      "Content:\n",
      "Subsequent sequence analysis and chromo- somal mapping studies revealed all three genes (neu, c-erbB-2, and HER-2) to be the same (22, 24, 25). A fourth group, also using v- erbB as a probe, identified the same gene in a mammary carcinoma cell line, MAC 117, where it was found to be amplified five- to ten- fold (26). This gene, which we will call HER-2/neu, encodes a new member of the tyrosine kinase family; and is dosely related to, but distinct from, the EGFR gene (22). HER-2/neu differs from EGFR in that itis found on band q21 of chromosome 17 (22, 24, 25), as compared to band pll.-p13 of chromosome 7, where the EGFR gene is located (27). Also, the HER-2/neu gene generates a messenger RNA (mRNA) of 4.8 kb (22), which differs from the 5.8- and 10- kb transcipts for the EGFR gene (28). Finally, the protein encoded by the HER-2/neu gene is 185,000 daltons (21), as compared to the 170,000-dalton protein encoded by the EGFR gene. Conversely, on the basis of sequence data, HER-2/neu is more closely related to the EGFR gene than to other members of the tyrosine kinase family (22). Like the EGFR protem, HER-2/neu has an extracellular domain, a transmembrane domain that includes two cysteine-rich repeat dusters, and an intracellular kinase domain (21), indicatingthat it too is likely to be a cellular receptor for an as yet unidentified ligand.\n",
      "\n",
      "Chunk length: 1370 characters\n",
      "Content:\n",
      "As a result of the published data showing amplification of HER- 2/neu in a human mammary carcinoma cell line, and as part of an ongoing survey in our laboratory of proto-oncogene abnormalities in human tumors, we evaluated alterations of the HER-2/neu gene in a large series of human primary breast cancers. Our results show that amplification of this gene occurs relatively frequently in breast cancer, and that it is associated with disease relapse and overall patient survival. Factors that are known to be important in the prognosis of breast malignancies in individual patients include: size of the primary tumor, stage of disease at diagnosis, hormonal receptor status, and number of axillary lymph nodes involved with disease (positive nodes) (29). The current study, which was conducted in two parts, involved the evaluation of tissue from 189 separate breast malignan- cies that were part of a breast cancer study ongoing at the University of Texas, San Antonio. This cohort of tumors was of interest because considerable information was available on the majority of the specimens including size of the primary tumor, estrogen recep- tor status, progesterone receptor status, age of patient, disease stage, and status of the axillary lymph nodes. In the initial survey, tissue from 103 primary breast cancers was evaluated for alterations in the HER-2/neu gene.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=150,\n",
    "    separators=[\"\\n\", \". \", \" \", \"\"],\n",
    "    keep_separator=\"end\",\n",
    ")\n",
    "chunks = text_splitter.split_text(article.body)\n",
    "\n",
    "print(f\"\\nNumber of chunks: {len(chunks)}\")\n",
    "print(f\"Average chunk length: {sum(len(chunk) for chunk in chunks) / len(chunks):.0f} characters\\n\")\n",
    "\n",
    "for chunk in chunks[:5]:\n",
    "    print(f\"Chunk length: {len(chunk)} characters\")\n",
    "    print(\"Content:\")\n",
    "    print(chunk + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d711212",
   "metadata": {},
   "source": [
    "Success!\n",
    "\n",
    "- The average chunk size is right around the upper bound of what is typical for abstracts. \n",
    "- From inspecting the first few chunks, successive chunks typically share one or more sentences or occur at a paragraph break in the article.\n",
    "\n",
    "## Keyword Extraction\n",
    "\n",
    "The next step is to extract keywords or phrases from each chunk. We will use these keywords/phrases to perform a hybrid search when a query comes in.\n",
    "\n",
    "We compute the keywords using the TextRank algorithm. At a high level, this algorithm works by creating a graph where \"words\" (after some pre-processing) are nodes and their connections are based on co-occurrence. The algorithm then applies PageRank to rank the nodes, identifying the most important words. These words can be aggreated into phrases or sentences in a post processing step. This is one of the main benefits of this algorithm over other common approaches (such as KeyBERT, RAKE, YAKE) which only return single words. For example, in our use-case we would want to identify \"breast cancer\" as a keyword, not just \"breast\" or \"cancer\".\n",
    "\n",
    "In this implementation we will use spacy's `en_core_web_sm` for the pre-processing (tokenization, lemmatization) and the PyTextRank library's implementation of the TextRank algorithm.\n",
    "\n",
    "Let's test it below on the first chunk, which happens to be exactly the abstract of the article.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2fff254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 phrases in the chunk:\n",
      "\n",
      "other known prognostic factors (rank: 0.1058, count: 1)\n",
      "breast cancer (rank: 0.1049, count: 1)\n",
      "thbis gene (rank: 0.1003, count: 1)\n",
      "HER-2/ neu (rank: 0.0973, count: 1)\n",
      "greater prognostic value (rank: 0.0911, count: 1)\n",
      "several disease parameters (rank: 0.0886, count: 1)\n",
      "distinct firom (rank: 0.0729, count: 1)\n",
      "189 primary human breast cancers (rank: 0.0713, count: 1)\n",
      "HER-2 (rank: 0.0704, count: 3)\n",
      "Am- plification (rank: 0.0698, count: 1)\n",
      "\n",
      "Original text:\n",
      "The HER-2/neu oncoFene is a member of the erbB-like oncogene family, and aS related to, but distinct firom, the epidermal growth factor receptr. This gene has been shown to be amplified i human brt cancer cell lines. In the current study, alterations of the gene in 189 primary human breast cancers were instigated HER-2/ neu was found to be amplified frm 2- to eater than 20- fold in 30% of the tumors. Correlation ofgene amplifica- tion with several disease parameters was evaluated Am- plification of the HER-2/neu gene was a significant pre- dictor of both overall survival and time to relapse in patients with breast cancer. It retained its significance even when adjustments were made for other known prognostic factors. Moreover, HER-2/neu amplification had greater prognostic value than most currently used prognostic factors, incuding hormonal-receptor status, in lymph node-positive disease. These data indicate that thbis gene may lay a role in the biologic behavior and/or pathogenesis human breast cancer.\n"
     ]
    }
   ],
   "source": [
    "chunk = chunks[0]\n",
    "\n",
    "# load a spaCy model, used for tokenization and lemmatization\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# add PyTextRank to the spaCy pipeline\n",
    "nlp.add_pipe(\"textrank\")\n",
    "doc = nlp(chunk)\n",
    "\n",
    "print(\"\\nTop 10 phrases in the chunk:\\n\")\n",
    "for phrase in doc._.phrases[:10]:\n",
    "    print(f\"{phrase.text} (rank: {phrase.rank:.4f}, count: {phrase.count})\")\n",
    "\n",
    "print(\"\\nOriginal text:\")\n",
    "print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ea3d74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
